// ğŸš€ æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒ•ãƒƒã‚¯
import { useState, useCallback, useMemo, useRef } from 'react';
import { cacheService } from '../utils/cacheService';

export interface OptimizedMessage {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
  cached?: boolean;
  performanceMetrics?: {
    responseTime: number;
    cacheHit: boolean;
    aiTime?: number;
    searchTime?: number;
  };
}

export interface ChatPerformanceStats {
  totalRequests: number;
  averageResponseTime: number;
  cacheHitRate: number;
  totalCacheHits: number;
  fastestResponse: number;
  slowestResponse: number;
}

export const useOptimizedChat = () => {
  const [messages, setMessages] = useState<OptimizedMessage[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [stats, setStats] = useState<ChatPerformanceStats>({
    totalRequests: 0,
    averageResponseTime: 0,
    cacheHitRate: 0,
    totalCacheHits: 0,
    fastestResponse: Infinity,
    slowestResponse: 0
  });

  const abortControllerRef = useRef<AbortController | null>(null);
  const performanceMetrics = useRef<number[]>([]);

  // ğŸ¯ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®æœ€é©åŒ–
  const sendOptimizedMessage = useCallback(async (
    content: string,
    ragEnabled: boolean = true
  ): Promise<void> => {
    if (!content.trim()) return;

    // é€²è¡Œä¸­ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }

    const startTime = performance.now();
    const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å³åº§ã«è¿½åŠ 
    const userMessage: OptimizedMessage = {
      id: messageId + '_user',
      role: 'user',
      content: content.trim(),
      timestamp: Date.now()
    };

    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);

    // æ–°ã—ã„AbortController
    abortControllerRef.current = new AbortController();

    try {
      // ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆå³åº§ã«ï¼‰
      const cacheKey = `${content}_rag_${ragEnabled}`;
      const cachedResponse = cacheService.get(cacheKey);

      if (cachedResponse) {
        const responseTime = performance.now() - startTime;
        
        const assistantMessage: OptimizedMessage = {
          id: messageId + '_assistant',
          role: 'assistant',
          content: cachedResponse.content,
          timestamp: Date.now(),
          cached: true,
          performanceMetrics: {
            responseTime,
            cacheHit: true
          }
        };

        setMessages(prev => [...prev, assistantMessage]);
        updatePerformanceStats(responseTime, true);
        setIsLoading(false);
        return;
      }

      // ğŸ“¡ APIå‘¼ã³å‡ºã—
      const response = await fetch('/api/openai/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${localStorage.getItem('token')}`
        },
        body: JSON.stringify({
          messages: [...messages, userMessage].map(msg => ({
            role: msg.role,
            content: msg.content
          })),
          ragEnabled
        }),
        signal: abortControllerRef.current.signal
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const data = await response.json();
      const responseTime = performance.now() - startTime;

      // ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º
      const performanceMetrics = {
        responseTime,
        cacheHit: data.cached || false,
        aiTime: data.performanceProfile?.aiTime,
        searchTime: data.performanceProfile?.searchTime
      };

      const assistantMessage: OptimizedMessage = {
        id: messageId + '_assistant',
        role: 'assistant',
        content: data.content,
        timestamp: Date.now(),
        cached: data.cached,
        performanceMetrics
      };

      setMessages(prev => [...prev, assistantMessage]);

      // ğŸ’¾ æ–°ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
      if (!data.cached) {
        cacheService.set(cacheKey, { content: data.content });
      }

      updatePerformanceStats(responseTime, data.cached);

    } catch (error: any) {
      if (error.name === 'AbortError') {
        console.log('ğŸš« ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ');
        return;
      }

      console.error('âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
      
      const errorMessage: OptimizedMessage = {
        id: messageId + '_error',
        role: 'assistant',
        content: 'ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
        timestamp: Date.now(),
        performanceMetrics: {
          responseTime: performance.now() - startTime,
          cacheHit: false
        }
      };

      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  }, [messages]);

  // ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
  const updatePerformanceStats = useCallback((responseTime: number, cacheHit: boolean) => {
    performanceMetrics.current.push(responseTime);
    
    setStats(prev => {
      const newTotalRequests = prev.totalRequests + 1;
      const newTotalCacheHits = prev.totalCacheHits + (cacheHit ? 1 : 0);
      
      // æœ€æ–°100ä»¶ã®å¹³å‡ã‚’è¨ˆç®—
      const recentMetrics = performanceMetrics.current.slice(-100);
      const averageResponseTime = recentMetrics.reduce((sum, time) => sum + time, 0) / recentMetrics.length;
      
      return {
        totalRequests: newTotalRequests,
        averageResponseTime,
        cacheHitRate: (newTotalCacheHits / newTotalRequests) * 100,
        totalCacheHits: newTotalCacheHits,
        fastestResponse: Math.min(prev.fastestResponse, responseTime),
        slowestResponse: Math.max(prev.slowestResponse, responseTime)
      };
    });
  }, []);

  // ğŸ—‘ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¯ãƒªã‚¢
  const clearMessages = useCallback(() => {
    setMessages([]);
    performanceMetrics.current = [];
    setStats({
      totalRequests: 0,
      averageResponseTime: 0,
      cacheHitRate: 0,
      totalCacheHits: 0,
      fastestResponse: Infinity,
      slowestResponse: 0
    });
  }, []);

  // ğŸ”„ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚­ãƒ£ãƒ³ã‚»ãƒ«
  const cancelRequest = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      setIsLoading(false);
    }
  }, []);

  // ğŸ¯ æœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆï¼ˆãƒ¡ãƒ¢åŒ–ï¼‰
  const optimizedMessages = useMemo(() => {
    return messages.map(msg => ({
      ...msg,
      // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¡¨ç¤ºç”¨ã®è¿½åŠ æƒ…å ±
      performanceLabel: msg.performanceMetrics ? (
        msg.performanceMetrics.cacheHit 
          ? `âš¡ ${msg.performanceMetrics.responseTime.toFixed(0)}ms (ã‚­ãƒ£ãƒƒã‚·ãƒ¥)`
          : `ğŸš€ ${msg.performanceMetrics.responseTime.toFixed(0)}ms`
      ) : undefined
    }));
  }, [messages]);

  // ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
  const getPerformanceAnalysis = useCallback(() => {
    const recentMetrics = performanceMetrics.current.slice(-20); // æœ€æ–°20ä»¶
    if (recentMetrics.length === 0) return null;

    const sorted = [...recentMetrics].sort((a, b) => a - b);
    const median = sorted[Math.floor(sorted.length / 2)];
    const p95 = sorted[Math.floor(sorted.length * 0.95)];

    return {
      ...stats,
      medianResponseTime: median,
      p95ResponseTime: p95,
      recentTrend: recentMetrics.length >= 5 ? 
        (recentMetrics.slice(-3).reduce((a, b) => a + b, 0) / 3) - 
        (recentMetrics.slice(0, 3).reduce((a, b) => a + b, 0) / 3) : 0
    };
  }, [stats]);

  return {
    messages: optimizedMessages,
    isLoading,
    stats,
    sendOptimizedMessage,
    clearMessages,
    cancelRequest,
    getPerformanceAnalysis
  };
};